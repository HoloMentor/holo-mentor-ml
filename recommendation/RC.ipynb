{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document as LCDocument\n",
    "from langchain_milvus.utils.sparse import BM25SparseEmbedding\n",
    "from typing import Iterator\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Files\\HM\\holo-mentor-ml\\hm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "class CustomDenseEmbedding(Embeddings):\n",
    "    def __init__(self, model_name='sentence-transformers/stsb-xlm-r-multilingual'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        inputs = self.tokenizer(texts, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        inputs = self.tokenizer([text], return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        return embedding.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from langchain_milvus.retrievers import MilvusCollectionHybridSearchRetriever\n",
    "from pymilvus.client.abstract import BaseRanker\n",
    "from typing import List\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-v2-m3')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-v2-m3')\n",
    "\n",
    "class CustomReranker(BaseRanker):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def rerank(self, query_text: str, retrieved_texts: List[str]) -> List[str]:\n",
    "        pairs = [[query_text, retrieved_text] for retrieved_text in retrieved_texts]\n",
    "        results = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for pair in pairs:\n",
    "                inputs = tokenizer(pair, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "                outputs = model(**inputs, return_dict=True)\n",
    "                logits = outputs.logits.squeeze(0)  #\n",
    "                if len(logits) == 1:\n",
    "                    score = logits[0].item()  \n",
    "                else:\n",
    "                    score = abs(logits[0] - logits[1]).item()  \n",
    "                results.append((pair[1], score))  \n",
    "\n",
    "        sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        reranked_texts = [text for text, score in sorted_results]\n",
    "\n",
    "        return reranked_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv(dotenv_path=\"../env\")\n",
    "\n",
    "db_host = os.getenv(\"DB_HOST\")\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "db_user = os.getenv(\"DB_USER\")\n",
    "db_password = os.getenv(\"DB_PASSWORD\")\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host,\n",
    "    database=db_name,\n",
    "    user=db_user,\n",
    "    password=db_password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wrong_questions(class_id, student_id,conn):\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    query = \"\"\"\n",
    "                SELECT qa.*\n",
    "                FROM quiz_answers qa\n",
    "                JOIN mcq_questions mq ON qa.mcq_question_id = mq.id\n",
    "                WHERE qa.user_id = %s\n",
    "                AND mq.class_id = %s\n",
    "                AND qa.answer != mq.answer\n",
    "                ORDER BY qa.created_at DESC\n",
    "                LIMIT 10;\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "    cur.execute(query, (student_id, class_id))\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    col_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "    result = [dict(zip(col_names, row)) for row in rows]\n",
    "\n",
    "    cur.close()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 4, 'user_id': 4, 'quiz_id': 2, 'mcq_question_id': 7, 'answer': 3, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 8, 'user_id': 4, 'quiz_id': 3, 'mcq_question_id': 6, 'answer': 4, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 10, 'user_id': 4, 'quiz_id': 2, 'mcq_question_id': 18, 'answer': 3, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 12, 'user_id': 4, 'quiz_id': 1, 'mcq_question_id': 16, 'answer': 4, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 19, 'user_id': 4, 'quiz_id': 2, 'mcq_question_id': 8, 'answer': 4, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 20, 'user_id': 4, 'quiz_id': 3, 'mcq_question_id': 8, 'answer': 4, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}, {'id': 22, 'user_id': 4, 'quiz_id': 1, 'mcq_question_id': 13, 'answer': 1, 'created_at': datetime.datetime(2024, 11, 28, 16, 20, 18, 132971)}]\n"
     ]
    }
   ],
   "source": [
    "wrong_questions = load_wrong_questions(1, 4, conn)\n",
    "print(wrong_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 6, 18, 16, 8, 8, 13]\n"
     ]
    }
   ],
   "source": [
    "wrong_mcq_question_ids = [q['mcq_question_id'] for q in wrong_questions]\n",
    "print(wrong_mcq_question_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 16, 'user_id': 2, 'question': [{'id': 'cea7c819-02ab-4074-9e2d-354832f38ed4', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'Hi ', 'type': 'text', 'styles': {}}, {'text': 'Hello Yaluwane', 'type': 'text', 'styles': {'textColor': 'orange'}}, {'text': ' Oyalata ', 'type': 'text', 'styles': {}}, {'text': 'kohomada', 'type': 'text', 'styles': {'italic': True}}, {'text': ' ithin bath ', 'type': 'text', 'styles': {}}, {'text': 'kawada', 'type': 'text', 'styles': {'bold': True}}, {'text': '???', 'type': 'text', 'styles': {}}], 'children': []}], 'answer': 1, 'class_id': 1, 'topic': '6', 'sub_topic': '6', 'mcq_answers': [{'index': 0, 'value': '3'}, {'index': 1, 'value': '34'}, {'index': 2, 'value': '45'}, {'index': 3, 'value': 'hghg'}, {'index': 4, 'value': '12'}], 'activation': 0}, {'id': 6, 'user_id': 2, 'question': [{'id': 'a999eb34-f80f-4b07-9a75-4163fee5b388', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'wefwefwe', 'type': 'text', 'styles': {}}], 'children': []}, {'id': 'd01dd3e9-3897-40f6-a1e8-f896c5de687f', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [], 'children': []}], 'answer': 3, 'class_id': 1, 'topic': '7', 'sub_topic': '7', 'mcq_answers': [{'index': 0, 'value': '1'}, {'index': 1, 'value': '2'}, {'index': 2, 'value': '3'}, {'index': 3, 'value': '3'}, {'index': 4, 'value': '2'}], 'activation': 0}, {'id': 8, 'user_id': 2, 'question': [{'id': 'e64adb1e-5fd9-4999-a349-8e1e7a82a80e', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'jhgf ygh uuyg uyguyh uyuygouuy', 'type': 'text', 'styles': {}}], 'children': []}, {'id': '863af04c-4e38-4336-9d42-f272fe2f34f8', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [], 'children': []}], 'answer': 2, 'class_id': 1, 'topic': '7', 'sub_topic': '7', 'mcq_answers': [{'index': 0, 'value': '1'}, {'index': 1, 'value': '3221'}, {'index': 2, 'value': '3211'}, {'index': 3, 'value': '2312'}, {'index': 4, 'value': '21312'}], 'activation': 1}, {'id': 13, 'user_id': 2, 'question': [{'id': 'cea7c819-02ab-4074-9e2d-354832f38ed4', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'Hi Hello Yaluwane Oyalata kohomada ithin bath kawada???', 'type': 'text', 'styles': {}}], 'children': []}], 'answer': 2, 'class_id': 1, 'topic': '6', 'sub_topic': '6', 'mcq_answers': [{'index': 0, 'value': '3'}, {'index': 1, 'value': '34'}, {'index': 2, 'value': '45'}, {'index': 3, 'value': 'hghg'}, {'index': 4, 'value': '12'}], 'activation': 1}, {'id': 18, 'user_id': 2, 'question': [{'id': 'b3e78234-eb7b-49d9-b149-8e0cce10fb18', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'uefb w  aeifhpiauewp', 'type': 'text', 'styles': {}}], 'children': []}], 'answer': 4, 'class_id': 1, 'topic': '7', 'sub_topic': '7', 'mcq_answers': [{'index': 0, 'value': '2'}, {'index': 1, 'value': '1'}, {'index': 2, 'value': '1'}, {'index': 3, 'value': '1'}, {'index': 4, 'value': '1'}], 'activation': 1}, {'id': 7, 'user_id': 2, 'question': [{'id': 'ab3a93ef-0c21-4923-b581-3feef9e3dafc', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [{'text': 'ok ok ok', 'type': 'text', 'styles': {}}], 'children': []}, {'id': 'b4cd8a6f-9365-4f19-bca4-4f8a2b23f87a', 'type': 'paragraph', 'props': {'textColor': 'default', 'textAlignment': 'left', 'backgroundColor': 'default'}, 'content': [], 'children': []}], 'answer': 0, 'class_id': 1, 'topic': '7', 'sub_topic': '7', 'mcq_answers': [{'index': 0, 'value': '1`'}, {'index': 1, 'value': '2'}, {'index': 2, 'value': 'thuna'}, {'index': 3, 'value': 'hghg'}, {'index': 4, 'value': 'yeas'}], 'activation': 0}]\n"
     ]
    }
   ],
   "source": [
    "def get_mcq_questions(wrong_mcq_question_ids, conn):\n",
    "    query = \"\"\"SELECT * FROM mcq_questions WHERE id IN %s\"\"\"\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query, (tuple(wrong_mcq_question_ids),))\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    col_names = [desc[0] for desc in cur.description]\n",
    "    wrong_mcq_questions = [dict(zip(col_names, row)) for row in rows]\n",
    "\n",
    "    return wrong_mcq_questions\n",
    "\n",
    "wrong_mcq_questions = get_mcq_questions(wrong_mcq_question_ids, conn)\n",
    "print(wrong_mcq_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [q['question'][0]['content'][0]['text']for q in wrong_mcq_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def embed_documents(wrong_mcq_questions, dense_embedding_instance, sparse_embedding_func):\n",
    "    embeddings_with_metadata = []\n",
    "\n",
    "    for doc in wrong_mcq_questions:\n",
    "        question_id = doc.get('id') \n",
    "        content_text = \" \".join([content.get('text', '') for content in doc.get('question', [{}])[0].get('content', [])])\n",
    "        \n",
    "        embeddings_with_metadata.append({\n",
    "            \"id\": question_id,\n",
    "            \"text\": content_text,\n",
    "            \"embedding\": dense_embedding_instance.embed_documents(content_text),  # Assuming embedding_func is defined\n",
    "            \"sparse\": sparse_embedding_func.embed_documents(content_text)[0],  # Assuming sparse_embedding_func is defined\n",
    "            \"metadata\": {\n",
    "                \"topic\": doc.get('topic'),\n",
    "                \"sub_topic\": doc.get('sub_topic'),\n",
    "                \"class_id\": doc.get('class_id')\n",
    "            }\n",
    "        })\n",
    "\n",
    "    for doc in embeddings_with_metadata:\n",
    "        doc[\"embedding\"] = doc[\"embedding\"].tolist()\n",
    "\n",
    "    return embeddings_with_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_embedding_func = BM25SparseEmbedding(corpus=texts)\n",
    "dense_embedding_instance = CustomDenseEmbedding()\n",
    "embeddings_with_metadata = embed_documents(wrong_mcq_questions, dense_embedding_instance, sparse_embedding_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/anuda/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from pymilvus import connections, Collection, FieldSchema, CollectionSchema, DataType, utility\n",
    "\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "\n",
    "collection_name = \"questioncollection\"\n",
    "\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'questioncollection' created successfully.\n",
      "Collection loaded: questioncollection\n"
     ]
    }
   ],
   "source": [
    "if not utility.has_collection(collection_name):\n",
    "    field1 = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False)\n",
    "    field2 = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768)  \n",
    "    field3 = FieldSchema(name=\"sparse\", dtype=DataType.SPARSE_FLOAT_VECTOR)  \n",
    "    field4 = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, is_primary=False, max_length=5000)  # Question content\n",
    "    field5 = FieldSchema(name=\"topic\", dtype=DataType.VARCHAR, is_primary=False, max_length=256)  # Topic\n",
    "    field6 = FieldSchema(name=\"sub_topic\", dtype=DataType.VARCHAR, is_primary=False, max_length=256)  # Sub-topic\n",
    "    field7 = FieldSchema(name=\"class_id\", dtype=DataType.INT64, is_primary=False)  # Class ID\n",
    "\n",
    "    # Create a collection schema\n",
    "    schema = CollectionSchema(\n",
    "        fields=[field1, field2, field3, field4, field5, field6, field7],\n",
    "        description=\"Collection for storing MCQ question embeddings with metadata\",\n",
    "        enable_dynamic_field=True\n",
    "    )\n",
    "\n",
    "    # Create the collection\n",
    "    collection = Collection(name=collection_name, schema=schema)\n",
    "\n",
    "    # Define and create indexes\n",
    "    embedding_index_params = {\"metric_type\": \"IP\", \"index_type\": \"IVF_FLAT\", \"params\": {\"nlist\": 128}}\n",
    "    collection.create_index(field_name=\"embedding\", index_params=embedding_index_params)\n",
    "\n",
    "    sparse_index = {\"index_type\": \"SPARSE_INVERTED_INDEX\", \"metric_type\": \"IP\"}\n",
    "    collection.create_index(field_name=\"sparse\", index_params=sparse_index)\n",
    "\n",
    "    # Flush the collection to persist changes\n",
    "    collection.flush()\n",
    "\n",
    "    print(f\"Collection '{collection_name}' created successfully.\")\n",
    "else:\n",
    "    # Load the existing collection\n",
    "    collection = Collection(name=collection_name)\n",
    "    print(f\"Collection '{collection_name}' already exists.\")\n",
    "\n",
    "# Confirm the collection is loaded\n",
    "print(f\"Collection loaded: {collection.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"id\": embeddings_with_metadata[i][\"id\"],\n",
    "        \"embedding\": embeddings_with_metadata[i][\"embedding\"],\n",
    "        \"sparse\": sparse_embedding_func.embed_documents([embeddings_with_metadata[i][\"text\"]])[0],  # Generate sparse embedding\n",
    "        \"text\": embeddings_with_metadata[i][\"text\"],\n",
    "        \"topic\": embeddings_with_metadata[i][\"metadata\"][\"topic\"],\n",
    "        \"sub_topic\": embeddings_with_metadata[i][\"metadata\"][\"sub_topic\"],\n",
    "        \"class_id\": embeddings_with_metadata[i][\"metadata\"][\"class_id\"]\n",
    "    }\n",
    "    for i in range(len(embeddings_with_metadata))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.insert(data)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'id': 7, 'topic': '7', 'sub_topic': '7', 'class_id': 1}, page_content='ok ok ok'), Document(metadata={'id': 6, 'topic': '7', 'sub_topic': '7', 'class_id': 1}, page_content='wefwefwe'), Document(metadata={'id': 18, 'topic': '7', 'sub_topic': '7', 'class_id': 1}, page_content='uefb w  aeifhpiauewp'), Document(metadata={'id': 13, 'topic': '6', 'sub_topic': '6', 'class_id': 1}, page_content='Hi Hello Yaluwane Oyalata kohomada ithin bath kawada???'), Document(metadata={'id': 16, 'topic': '6', 'sub_topic': '6', 'class_id': 1}, page_content='Hi  Hello Yaluwane  Oyalata  kohomada  ithin bath  kawada ???')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_milvus.retrievers import MilvusCollectionHybridSearchRetriever\n",
    "\n",
    "\n",
    "sparse_search_params = {\"metric_type\": \"IP\"}\n",
    "dense_search_params = {\"metric_type\": \"IP\", \"params\": {}}\n",
    "\n",
    "reranker = CustomReranker()\n",
    "\n",
    "retriever = MilvusCollectionHybridSearchRetriever(\n",
    "    collection=collection,\n",
    "    rerank=reranker,\n",
    "    anns_fields=[\"embedding\", \"sparse\"],  # Fields to search in Milvus\n",
    "    field_embeddings=[dense_embedding_instance, sparse_embedding_func],  # Embedding functions\n",
    "    field_search_params=[dense_search_params, sparse_search_params],  # Search parameters for embeddings\n",
    "    top_k=5,  \n",
    "    text_field=\"text\",  \n",
    "    filter_fields=[\"topic\", \"sub_topic\", \"class_id\"],  \n",
    ")\n",
    "\n",
    "filter_criteria = {\n",
    "    \"topic\": 7,  \n",
    "    \"sub_topic\": 7 ,  \n",
    "    \"class_id\": 1 \n",
    "}\n",
    "\n",
    "query = \"OK OK OK OK\"\n",
    "retrieved_docs = retriever.invoke(query, filters=filter_criteria)\n",
    "\n",
    "print(retrieved_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 6, 18, 13, 16]\n"
     ]
    }
   ],
   "source": [
    "extracted_ids = [doc.metadata['id'] for doc in retrieved_docs]\n",
    "print(extracted_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
